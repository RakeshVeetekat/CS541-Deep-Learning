{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "starting_x_tr = np.reshape(np.load(\"fashion_mnist_train_images.npy\"), (-1, 28*28))\n",
    "starting_y_tr = np.load(\"fashion_mnist_train_labels.npy\")\n",
    "x_te = np.reshape(np.load(\"fashion_mnist_test_images.npy\"), (-1, 28*28))\n",
    "y_te = np.load(\"fashion_mnist_test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "starting_x_tr = starting_x_tr/255\n",
    "x_te = x_te/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding function\n",
    "def to_one_hot(y):\n",
    "    shape = (y.size, int(np.max(y) + 1))\n",
    "    rows = np.arange(y.size)\n",
    "    one_hot = np.zeros(shape)\n",
    "    one_hot[rows, y] = 1.\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (48000, 784)\n",
      "X_val size: (12000, 784)\n",
      "y_train size: (48000,)\n",
      "y_val size: (12000,)\n"
     ]
    }
   ],
   "source": [
    "# Split training data to create validation datasets\n",
    "x_train, x_val, y_train, y_val = train_test_split(starting_x_tr, starting_y_tr, train_size=0.8)\n",
    "print(\"X_train size:\", x_train.shape)\n",
    "print(\"X_val size:\", x_val.shape)\n",
    "print(\"y_train size:\", y_train.shape)\n",
    "print(\"y_val size:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 10)\n",
      "(12000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Converting y training, validation, and testing sets to one-hot encoded\n",
    "y_train_one_hot = to_one_hot(y_val)\n",
    "print(y_train_one_hot.shape)\n",
    "\n",
    "y_val_one_hot = to_one_hot(y_val)\n",
    "print(y_val_one_hot.shape)\n",
    "\n",
    "y_te_one_hot = to_one_hot(y_te)\n",
    "print(y_te_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = z - np.max(z)\n",
    "    bottom = np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    return np.exp(z) / bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross-entropy loss\n",
    "def crossentropy(y, y_hat):\n",
    "    return -np.mean(np.sum(np.log(y_hat) * y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of correct predictions\n",
    "def computeAccuracy(y, y_hat):\n",
    "    return np.mean(np.argmax(y_hat, axis=1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the gradient step\n",
    "def gradient_descent(y_hat, x, y, b, w, learn_rate, m, alpha):\n",
    "    cost = y_hat - y\n",
    "    reg = alpha * w\n",
    "    gradW = 1/m * x.T.dot(cost) + reg\n",
    "    gradB = 1/m * np.sum(cost, axis=0)\n",
    "    w = w - learn_rate * gradW\n",
    "    b = b - learn_rate * gradB\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the samples based on the batch_size hyperparameter\n",
    "def batch_loop(x, y, size):\n",
    "\tif(len(x) == len(y)):\n",
    "\t\trandom_x = x[np.random.permutation(x.shape[0])]\n",
    "\t\trandom_y = y[np.random.permutation(y.shape[0])]\n",
    "\t\tfor i in np.arange(0, y.shape[0], size):\n",
    "\t\t\tyield random_x[i:i + size], random_y[i:i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SGD\n",
    "def stochastic_gradient_descent(x, y, b, w, learn_rate, num_of_epoch, batch_size, alpha):\n",
    "\t\n",
    "\tfor n in range(num_of_epoch - 1):\n",
    "\t\tfor mini_batch_x, mini_batch_y in batch_loop(x, y, batch_size):\n",
    "\t\t\tz = mini_batch_x[:batch_size].dot(w)\n",
    "\t\t\ty_hat = softmax(z)\n",
    "\t\t\tw, b = gradient_descent(y_hat, mini_batch_x[:batch_size], mini_batch_y[:batch_size], b, w, learn_rate, batch_size, alpha)\n",
    "\t\t\n",
    "\t# return w, b \n",
    "\treturn w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the lowest error by performing SGD\n",
    "def train_w_and_b(x, y, learn_rate, num_of_epoch, batch_size, alpha):\n",
    "\tw = np.random.randn(x.shape[1], len(np.unique(y)))\n",
    "\tb = np.random.rand(len(np.unique(y)))\n",
    "\ty = to_one_hot(y)\n",
    "\tw_trained, b_trained = stochastic_gradient_descent(x, y, b, w, learn_rate, num_of_epoch, batch_size, alpha)\n",
    "\treturn w_trained, b_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of grid_search to tune our hyperparameters by looping through the various values we have for each\n",
    "def grid_search():\n",
    "\thyperparameters = {\n",
    "\t\t\"learn_rate\": [0.25, 0.1, 0.01],\n",
    "\t\t\"num_of_epoch\": [30, 40, 50],\n",
    "\t\t\"batch_size\": [50, 100, 200],\n",
    "\t\t\"alpha\": [0.25, 0.1, 0.01]\t\n",
    "\t}\n",
    "\tfor a in range(len(hyperparameters[\"num_of_epoch\"])):\n",
    "\t\tfor b in range(len(hyperparameters[\"batch_size\"])):\n",
    "\t\t\tfor c in range(len(hyperparameters[\"learn_rate\"])):\n",
    "\t\t\t\tfor d in range(len(hyperparameters[\"alpha\"])):\n",
    "\t\t\t\t\t\tyield hyperparameters[\"num_of_epoch\"][a], hyperparameters[\"batch_size\"][b], hyperparameters[\"learn_rate\"][c], hyperparameters[\"alpha\"][d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3 Output:\n",
      "\n",
      "Number of epochs:  30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss:  4.148856882081146\n",
      "Percent of correctly classified examples:  0.14016666666666666\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.114516978707293\n",
      "Percent of correctly classified examples:  0.18633333333333332\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.6030455363868406\n",
      "Percent of correctly classified examples:  0.10591666666666667\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.554560461904809\n",
      "Percent of correctly classified examples:  0.12241666666666666\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3254771277535196\n",
      "Percent of correctly classified examples:  0.18258333333333332\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.5040727554269933\n",
      "Percent of correctly classified examples:  0.12766666666666668\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3002580769682934\n",
      "Percent of correctly classified examples:  0.11275\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.2937962316550315\n",
      "Percent of correctly classified examples:  0.10525\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3054041221229005\n",
      "Percent of correctly classified examples:  0.11341666666666667\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.7100869707514423\n",
      "Percent of correctly classified examples:  0.09533333333333334\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  4.960282519319692\n",
      "Percent of correctly classified examples:  0.09858333333333333\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.480067705292034\n",
      "Percent of correctly classified examples:  0.12716666666666668\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3122958439088275\n",
      "Percent of correctly classified examples:  0.05125\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3691313418804665\n",
      "Percent of correctly classified examples:  0.10308333333333333\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.341595839375785\n",
      "Percent of correctly classified examples:  0.09866666666666667\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3094772538499946\n",
      "Percent of correctly classified examples:  0.11008333333333334\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3224192561245838\n",
      "Percent of correctly classified examples:  0.10416666666666667\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.4722031470475754\n",
      "Percent of correctly classified examples:  0.09566666666666666\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.395240010434468\n",
      "Percent of correctly classified examples:  0.03525\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.5548679201080393\n",
      "Percent of correctly classified examples:  0.13991666666666666\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.1024584950855356\n",
      "Percent of correctly classified examples:  0.09616666666666666\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.418520670700819\n",
      "Percent of correctly classified examples:  0.0795\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3105674645022716\n",
      "Percent of correctly classified examples:  0.10583333333333333\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.3655328967926503\n",
      "Percent of correctly classified examples:  0.13325\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.311671670459128\n",
      "Percent of correctly classified examples:  0.06283333333333334\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  2.314811353305672\n",
      "Percent of correctly classified examples:  0.12208333333333334\n",
      "Number of epochs:  30\n",
      "Cross-entropy loss:  3.2073985624220707\n",
      "Percent of correctly classified examples:  0.10391666666666667\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  5.894369250530957\n",
      "Percent of correctly classified examples:  0.057166666666666664\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  3.6102047870720995\n",
      "Percent of correctly classified examples:  0.09891666666666667\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  4.542193575612371\n",
      "Percent of correctly classified examples:  0.10275\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.745627753010895\n",
      "Percent of correctly classified examples:  0.0945\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.6550578410907217\n",
      "Percent of correctly classified examples:  0.09675\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.426222730808983\n",
      "Percent of correctly classified examples:  0.10358333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.3062570993948235\n",
      "Percent of correctly classified examples:  0.10441666666666667\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.2750501887397636\n",
      "Percent of correctly classified examples:  0.13875\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.349399273460016\n",
      "Percent of correctly classified examples:  0.05583333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  3.296300023709709\n",
      "Percent of correctly classified examples:  0.1035\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  4.266265353445718\n",
      "Percent of correctly classified examples:  0.10225\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  4.156357275572532\n",
      "Percent of correctly classified examples:  0.09875\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.328613089728934\n",
      "Percent of correctly classified examples:  0.03883333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.2973035459082554\n",
      "Percent of correctly classified examples:  0.146\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.307083077119004\n",
      "Percent of correctly classified examples:  0.08058333333333334\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.314354581805551\n",
      "Percent of correctly classified examples:  0.015333333333333332\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.30008136453898\n",
      "Percent of correctly classified examples:  0.05566666666666667\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.325741823910072\n",
      "Percent of correctly classified examples:  0.124\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  3.1926228782384607\n",
      "Percent of correctly classified examples:  0.10333333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  3.011074817994023\n",
      "Percent of correctly classified examples:  0.10033333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  3.8072491495353393\n",
      "Percent of correctly classified examples:  0.10158333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.3214854285848285\n",
      "Percent of correctly classified examples:  0.12775\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.3090356308129563\n",
      "Percent of correctly classified examples:  0.10033333333333333\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.363320876139569\n",
      "Percent of correctly classified examples:  0.09825\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.297987791194753\n",
      "Percent of correctly classified examples:  0.06266666666666666\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.298312206836639\n",
      "Percent of correctly classified examples:  0.07341666666666667\n",
      "Number of epochs:  40\n",
      "Cross-entropy loss:  2.772832141648051\n",
      "Percent of correctly classified examples:  0.09983333333333333\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  3.356661207202178\n",
      "Percent of correctly classified examples:  0.12775\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  4.08759436934761\n",
      "Percent of correctly classified examples:  0.09566666666666666\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  5.756551173981299\n",
      "Percent of correctly classified examples:  0.059083333333333335\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.4720268505116514\n",
      "Percent of correctly classified examples:  0.023083333333333334\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.4191864389519706\n",
      "Percent of correctly classified examples:  0.10658333333333334\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.4948220556259706\n",
      "Percent of correctly classified examples:  0.12816666666666668\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3129110666956243\n",
      "Percent of correctly classified examples:  0.0855\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3089985506737127\n",
      "Percent of correctly classified examples:  0.08741666666666667\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3252019703473166\n",
      "Percent of correctly classified examples:  0.12825\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  4.898206629772156\n",
      "Percent of correctly classified examples:  0.10175\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  5.3250519070636155\n",
      "Percent of correctly classified examples:  0.1025\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  3.4192158366284984\n",
      "Percent of correctly classified examples:  0.0905\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.4473583252129893\n",
      "Percent of correctly classified examples:  0.10175\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3589576882786267\n",
      "Percent of correctly classified examples:  0.10858333333333334\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3676430453751416\n",
      "Percent of correctly classified examples:  0.08975\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.313546152087616\n",
      "Percent of correctly classified examples:  0.12225\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.30412363812223\n",
      "Percent of correctly classified examples:  0.1035\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.2936741716328877\n",
      "Percent of correctly classified examples:  0.12875\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.8947963493362767\n",
      "Percent of correctly classified examples:  0.10141666666666667\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.798379604604758\n",
      "Percent of correctly classified examples:  0.10225\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  3.9121897572683797\n",
      "Percent of correctly classified examples:  0.10191666666666667\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.315620594336094\n",
      "Percent of correctly classified examples:  0.05533333333333333\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3130513360918976\n",
      "Percent of correctly classified examples:  0.004416666666666667\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3041466341129637\n",
      "Percent of correctly classified examples:  0.11666666666666667\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.3035008438442044\n",
      "Percent of correctly classified examples:  0.13716666666666666\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.303959100490367\n",
      "Percent of correctly classified examples:  0.13308333333333333\n",
      "Number of epochs:  50\n",
      "Cross-entropy loss:  2.551018897600592\n",
      "Percent of correctly classified examples:  0.09958333333333333\n",
      "\n",
      "\n",
      "Results of training:\n",
      "best cross-entropy loss from validation dataset:  2.2750501887397636\n",
      "best accuracy from validation dataset:  0.13875\n",
      "best learning rate:  0.01\n",
      "best number of epochs:  40\n",
      "best batch size:  50\n",
      "best reg term:  0.1\n",
      "Cross-entropy loss from test dataset:  2.5269889415065774\n",
      "Percent of correctly classified examples from test dataset:  0.1064\n"
     ]
    }
   ],
   "source": [
    "# Initialize best hyperparameter values as the worst they could be\n",
    "best_CE_loss = 1000000\n",
    "best_accuracy = -1\n",
    "best_num_of_epoch = -1\n",
    "best_batch_size = -1\n",
    "best_learn_rate = -1\n",
    "best_alpha = -1\n",
    "y_val_one_hot = to_one_hot(y_val)\n",
    "\n",
    "print(\"Problem 3 Output:\\n\")\n",
    "\n",
    "# Loop through each combination of the hyperparameters in grid_search() to find the best combination to minimize MSE\n",
    "for num_of_epoch, batch_size, learn_rate, alpha in grid_search():\n",
    "\n",
    "\t# Print number of epochs used for each loop\n",
    "\tprint(\"Number of epochs: \", num_of_epoch)\n",
    "\n",
    "\t# w_trained, b_trained = find_lowest_error(x_train, y_train, learn_rate, num_of_epoch, batch_size, alpha)\n",
    "\tw_trained, b_trained = train_w_and_b(x_train, y_train, learn_rate, num_of_epoch, batch_size, alpha)\n",
    "\n",
    "\t# Calculate the cross-entropy loss and accuracy\n",
    "\tz = x_val@(w_trained)\n",
    "\ty_hat = softmax(z)\n",
    "\tCE_loss = crossentropy(y_val_one_hot, y_hat)\n",
    "\taccuracy = computeAccuracy(y_val, y_hat)\n",
    "\tprint(\"Cross-entropy loss: \", CE_loss)\n",
    "\tprint(\"Percent of correctly classified examples: \", accuracy) \n",
    "\n",
    "\t# Store the hyperparameters that led to reduced error in the following variables\n",
    "\tif CE_loss < best_CE_loss:\n",
    "\t\tbest_CE_loss = CE_loss\n",
    "\t\tbest_accuracy = accuracy\n",
    "\t\tbest_learn_rate = learn_rate\n",
    "\t\tbest_num_of_epoch = num_of_epoch\n",
    "\t\tbest_batch_size = batch_size\n",
    "\t\tbest_alpha = alpha\n",
    "\n",
    "# Finally, calculate the error using the trained weights and biases\n",
    "z = x_te@(w_trained)\n",
    "y_hat = softmax(z)\n",
    "CE_loss = crossentropy(y_te_one_hot, y_hat)\n",
    "accuracy = computeAccuracy(y_te, y_hat)\n",
    "print(\"\\n\")\n",
    "print(\"Results of training:\")\n",
    "print(\"best cross-entropy loss from validation dataset: \", best_CE_loss)\n",
    "print(\"best accuracy from validation dataset: \", best_accuracy)\n",
    "print(\"best learning rate: \", best_learn_rate)\n",
    "print(\"best number of epochs: \", best_num_of_epoch)\n",
    "print(\"best batch size: \", best_batch_size)\n",
    "print(\"best reg term: \", best_alpha)\n",
    "print(\"Cross-entropy loss from test dataset: \", CE_loss)\n",
    "print(\"Percent of correctly classified examples from test dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4 Output:\n",
      "z =  \n",
      " [array([[1],\n",
      "       [1],\n",
      "       [4]]), array([0.])]\n",
      "gradients of z:  \n",
      " (array([[0.75],\n",
      "       [0.  ]]), array([[-0.75],\n",
      "       [ 0.  ]]))\n"
     ]
    }
   ],
   "source": [
    "# Problem 4\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "W1 = np.array([[1, 2], [0, 1], [-1, 0]])\n",
    "b1 = np.array([[0],[0], [3]])\n",
    "W2 = np.array([1, -2, 1/4])\n",
    "b2 = [0]\n",
    "L = [[W1, b1], [W2, b2]]\n",
    "x = np.array([[-1], [1]])\n",
    "\n",
    "def affineTransformation(W, b, x):\n",
    "    y = np.matmul(W,x) + b\n",
    "    return y\n",
    "\n",
    "def composition(L, x):\n",
    "    f = []\n",
    "    for i in range(len(L)):\n",
    "        y = affineTransformation(L[i][0], L[i][1], x)\n",
    "        f.append(y)\n",
    "        x = y\n",
    "    return f\n",
    "\n",
    "def computeGradients(L, z, x):\n",
    "    W = list(zip(*L))[0]\n",
    "    gradw = np.matmul(np.transpose(W[0]), W[1].reshape(-1,1))\n",
    "    gradb = np.matmul(np.transpose(W[0]), W[1].reshape(-1,1))*x\n",
    "    return gradw, gradb\n",
    "\n",
    "print(\"Problem 4 Output:\")\n",
    "print(\"z = \", '\\n', composition(L, x))\n",
    "print(\"gradients of z: \", '\\n', computeGradients(L,composition(L,x),x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
